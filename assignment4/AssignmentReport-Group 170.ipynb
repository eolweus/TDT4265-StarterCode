{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "IoU or intersection of Union is a measurement of accuracy for object detection models. It takes the overlap between the ground truth bounding box, and the predicted bounding box, and divides it on the area of the union.\n",
    "\n",
    "![Task1a](hand_written_notes/task1a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "\n",
    "A True Positive is the part of a prediction which intersects with the ground truth. A false Positive is the part of a prediction which does not intersect with the ground truth.\n",
    "\n",
    "![Task1b](hand_written_notes/Task1b.png)\n",
    "\n",
    "## task 1c)\n",
    "\n",
    "mAP: 0.64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "### Task 2f)\n",
    "![precision recall curve](task2/precision_recall_curve.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a)\n",
    "\n",
    "The operation of filtering out overlapping bounding boxes during inference is called **non-maximum suppression**.\n",
    "\n",
    "### Task 3b)\n",
    "*Predictions from the deeper layers in SSD are responsible to\n",
    "detect small objects.*\n",
    "\n",
    "This is **false**. The deeper we go into the network, the lower the resolution becomes. The higher resolution feature maps are responsible for detecting smaller objects, meaning the more \"shallow\" or higher layers preform this task.\n",
    "\n",
    "### Task 3c)\n",
    "We use different bounding box aspect ratios at the same spatial location because it enhances the early stage of training. If we have diverse box shapes, it is easier to detect multiple objects with varying shapes. This makes sense as a lot of objects in real life do not have random aspect ratios (Humans for instance are typically way longer than they are wide), and therefore applying different default boxes will increase the chance that one of them become a positive match. This again is important for training as *SSD only uses positive matches in calculating the localization cost* as stated in the medium article by Jonathan Hui.\n",
    "\n",
    "\n",
    "### Task 3d)\n",
    "What is the main difference between SSD and YOLOv1/v2 (The YOLO version they refer\n",
    "to in the SSD paper)?\n",
    "\n",
    "The difference is that the SSD model adds extra feature layers to the end of the base network. *which predict\n",
    "the offsets to default boxes of different scales and aspect ratios and their associated\n",
    "confidences*.\n",
    "\n",
    "Essensially, YOLO operates on a single scale feature map, while SSD operates on several which allows it to detect objects in a wide range of scales. The SSD also uses convolutional filters to determine the shape offsets relative to the default boxes coordinates, where as YOLO uses a dense layer for this task.\n",
    "\n",
    "### Task 3e)\n",
    "38x38x6 = 8664 anchor boxes for the feature map\n",
    "\n",
    "### Task 3f)\n",
    "38 x 38 x 6 = 8664\n",
    "19 x 19 x 6 = 2166\n",
    "10 x 10 x 6 = 600\n",
    "5 x 5 x 6 = 150\n",
    "3 x 3 x 6 = 54\n",
    "1 x 1 x 6 = 6\n",
    "  \n",
    "  =  11640 total anchor boxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "\n",
    "![total_loss](plots/total_loss_task4b.png) \n",
    "I trained for 10k iterations\n",
    "\n",
    "mAP after 6k iterations: 0.7576\n",
    "Final mAP: 0.8008\n",
    "\n",
    "## Task 4c)\n",
    "I got to 0.8708 mAP by adding two extra conv layers with more filters in the backbone, and adding batchnormalization before all conv layers. Additionally I set learning rate to 1e-3\n",
    "\n",
    "mAP: 0.8710\n",
    "\n",
    "| number | AP       |\n",
    "|--------|----------|\n",
    "| 0      | : 0.8892 |\n",
    "| 1      | : 0.8618 |\n",
    "| 2      | : 0.8540 |\n",
    "| 3      | : 0.8552 |\n",
    "| 4      | : 0.8798 |\n",
    "| 5      | : 0.8590 |\n",
    "| 6      | : 0.8874 |\n",
    "| 7      | : 0.8654 |\n",
    "| 8      | : 0.8924 |\n",
    "| 9      | : 0.8656 |\n",
    "\n",
    "\n",
    "\n",
    "****************\n",
    "\n",
    "### Backbone\n",
    "\n",
    "| Layer | LayerType | Number of Hidden Units/filters | stride |\n",
    "|-------|-----------|--------------------------------|--------|\n",
    "| 1     | conv2d    | 32                             | 1      |\n",
    "| -     | MaxPool2d | -                              | 2      |\n",
    "| -     | ReLU      | -                              | -      |\n",
    "| 2     | conv2d    | 64                             | 1      |\n",
    "| -     | MaxPool2d | -                              | 2      |\n",
    "| -     | ReLU      | -                              | -      |\n",
    "| 3     | conv2d    | 128                            | 1      |\n",
    "| -     | ReLU      | -                              | -      |\n",
    "| 4     | conv2d    | 128                            | 1      |\n",
    "| -     | ReLU      | -                              | -      |\n",
    "| 5     | conv2d    | 64                             | 1      |\n",
    "| -     | ReLU      | -                              | -      |\n",
    "| 6     | conv2d    | 64                             | 2      |\n",
    "\n",
    "please note that I use a nn.BatchNorm2d layer after every conv layer\n",
    "\n",
    "\n",
    "## Task 4d)\n",
    "To get the mAP above 90% i changed the optimizer to Adam, set the learning rate to 5e-4, and added a couple of more filters and layers. already by 6.5k iterations the mAP was at 0.9015.\n",
    "the mAP was at its highest after 8.5k iterations at 0.9029. Also, I'm still using batchnormalization before every conv\n",
    "\n",
    "mAP: 0.9029\n",
    "\n",
    "| number | AP       |\n",
    "|--------|----------|\n",
    "| 0      | : 0.9032 |\n",
    "| 1      | : 0.8985 |\n",
    "| 2      | : 0.9053 |\n",
    "| 3      | : 0.9061 |\n",
    "| 4      | : 0.9046 |\n",
    "| 5      | : 0.8971 |\n",
    "| 6      | : 0.9037 |\n",
    "| 7      | : 0.9030 |\n",
    "| 8      | : 0.9069 |\n",
    "| 9      | : 0.9006 |\n",
    "\n",
    "************************\n",
    "\n",
    "I also made significant changes to the architecture of the network\n",
    "\n",
    "### Backbone\n",
    "\n",
    "| Layer      | LayerType | Number of Hidden Units/filters | stride |\n",
    "|------------|-----------|--------------------------------|--------|\n",
    "| 1          | conv2d    | 32                             | 1      |\n",
    "| -          | MaxPool2d | -                              | 2      |\n",
    "| -          | ReLU      | -                              | -      |\n",
    "| 2          | conv2d    | 64                             | 1      |\n",
    "| -          | MaxPool2d | -                              | 2      |\n",
    "| -          | ReLU      | -                              | -      |\n",
    "| 3          | conv2d    | 128                            | 1      |\n",
    "| -          | ReLU      | -                              | -      |\n",
    "| 4          | conv2d    | 256                            | 1      |\n",
    "| -          | ReLU      | -                              | -      |\n",
    "| 5          | conv2d    | 256                            | 1      |\n",
    "| -          | ReLU      | -                              | -      |\n",
    "| 6          | conv2d    | 256                            | 1      |\n",
    "| -          | ReLU      | -                              | -      |\n",
    "| 7 (output) | conv2d    | 256                            | 2      |\n",
    "\n",
    "### Extra filters\n",
    "\n",
    "| Layer      | LayerType | Number of Hidden Units/filters | stride |\n",
    "|------------|-----------|--------------------------------|--------|\n",
    "| -          | ReLuU     | -                              | -      |\n",
    "| 8          | conv2d    | 256                            | 1      |\n",
    "| -          | ReLU      | -                              | -      |\n",
    "| 9 (output) | conv2d    | 512                            | 2      |\n",
    "\n",
    "****************************\n",
    "\n",
    "| Layer      | LayerType | Number of Hidden Units/filters | stride |\n",
    "|------------|-----------|--------------------------------|--------|\n",
    "| -          | ReLuU     | -                              | -      |\n",
    "| 10         | conv2d    | 512                            | 1      |\n",
    "| -          | ReLU      | -                              | -      |\n",
    "| 11 (output)| conv2d    | 256                            | 2      |\n",
    "\n",
    "***************************\n",
    "\n",
    "| Layer      | LayerType | Number of Hidden Units/filters | stride |\n",
    "|------------|-----------|--------------------------------|--------|\n",
    "| -          | ReLuU     | -                              | -      |\n",
    "| 12         | conv2d    | 256                            | 1      |\n",
    "| -          | ReLU      | -                              | -      |\n",
    "| 13 (output)| conv2d    | 256                            | 2      |\n",
    "\n",
    "***************************\n",
    "\n",
    "| Layer      | LayerType | Number of Hidden Units/filters | stride |\n",
    "|------------|-----------|--------------------------------|--------|\n",
    "| -          | ReLuU     | -                              | -      |\n",
    "| 14         | conv2d    | 256                            | 1      |\n",
    "| -          | ReLU      | -                              | -      |\n",
    "| 15 (output)| conv2d    | 128                            | 2      |\n",
    "\n",
    "***************************\n",
    "\n",
    "| Layer      | LayerType | Number of Hidden Units/filters | stride |\n",
    "|------------|-----------|--------------------------------|--------|\n",
    "| -          | ReLuU     | -                              | -      |\n",
    "| 16         | conv2d    | 128                            | 1      |\n",
    "| -          | ReLU      | -                              | -      |\n",
    "| 17 (output)| conv2d    | 128                            | 1      |\n",
    "\n",
    "\n",
    "\n",
    "***************************\n",
    "\n",
    "## Task 4e)\n",
    "\n",
    "![0](SSD/demo/mnist/result/0.png)\n",
    "![1](SSD/demo/mnist/result/1.png)\n",
    "![2](SSD/demo/mnist/result/2.png)\n",
    "![3](SSD/demo/mnist/result/3.png)\n",
    "![4](SSD/demo/mnist/result/4.png)\n",
    "![5](SSD/demo/mnist/result/5.png)\n",
    "![6](SSD/demo/mnist/result/6.png)\n",
    "![7](SSD/demo/mnist/result/7.png)\n",
    "![8](SSD/demo/mnist/result/8.png)\n",
    "![9](SSD/demo/mnist/result/9.png)\n",
    "![10](SSD/demo/mnist/result/10.png)\n",
    "![11](SSD/demo/mnist/result/11.png)\n",
    "![12](SSD/demo/mnist/result/12.png)\n",
    "![13](SSD/demo/mnist/result/13.png)\n",
    "![14](SSD/demo/mnist/result/14.png)\n",
    "\n",
    "We see that my model struggled quite a lot with the really small numbers. It also makes a few mistakes, and sometimes can't detect numbers that are overlapping\n",
    "\n",
    "## Task 4f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('py38': conda)",
   "language": "python",
   "name": "python38164bitpy38condac1f68ca5407a4349b0d7e37676f2fbb3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}